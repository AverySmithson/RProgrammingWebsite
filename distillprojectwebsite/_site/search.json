{
  "articles": [
    {
      "path": "about.html",
      "title": "About",
      "description": "This website is meant to serve as a intro guide for anyone wanting to learn the basics about how programming in R works (specifically for statsitical purposes). Once you have these basics down, I hope it will help you to be more confident in learning how to do more advanced things using R. All the data I use comes from Our World in Data, specifially the mental health data. I was able to find and use a package to bring this data into R to make that process a little bit easier. \n\nI hope you find my tips about R useful@",
      "author": [],
      "contents": "\n\n\n\n",
      "last_modified": "2021-12-16T17:46:56+00:00"
    },
    {
      "path": "index.html",
      "title": "Intro Guide to Programming in R",
      "description": "Welcome to my website. I hope you enjoy it and learn the basics of R programming!\n",
      "author": [],
      "contents": "\nSome Tips About R Syntax\nHere are some basics about R syntax and some tips to keep in mind along the way:\nTo leave a comment or note in your code that you do not want R to read, use a #. #Example: R is not going to read this chunk of text because I started this line with a #. If your comment is more than one line, each line must start with a #. Leaving comments is such an important part of coding in any language. Use comments to your advantage to make your code more readable. Using comments helps others and yourself understand your code. If you walk away from your code and at a later time can’t recall the goal, that means someone else likely won’t understand either and you should add more/better comments!\nTo run a chunk of code in R, simply put your cursor anywhere with in that chunk of code and hit control + enter (or command + return for Mac’s) on your keyboard.\nMost of the time, strings of text need to be captured in quotation marks for R to understand what you are trying to say.\nI recommend typing your code in the R-script window as this allows you to make edits and corrections to your code\nWhen installing packages, the package name must be enclosed in quotations and parentheses\nAlways make sure your parentheses and quotation marks have and opening and closing. Forgetting to close a parenthesis or quotation will result in an error. The easiest way to avoid this error is making sure your parentheses and quotation marks are closed before adding any text to them. You can also turn on rainbow parentheses in settings by going to code in the menu bar and then selecting rainbow parentheses.\n\n\nManaging Data\nIn this section I want to discuss and demonstrate some ways to manage data using the tidyverse package and janitor package. The tidyverse package has several other packages within it that I will be using throughout the rest of the website (mainly dplyr, tibble, and ggplot2). The janitor package will be used to help us clean up variable names as necessary.\nStep 1: Lets make sure all the packages we will need are installed at the beginning so they will be easy to find later. The tidyverse and janitor packages will help us to manage and visualize our data, and the owidR package is where I will be accessing all of the data I want to use. This data comes from Our World in Data: Mental Health Data.\n\n\n\nBelow I am using the search function from the owidR package to find a dataset of interset. Then, I am assigning the dataset of interest to the name “substancedisorder”. Next, I am viewing the raw dataset and turning it into a tibble so that it is easier for R to work with since this is a very large dataset.\n\n# A tibble: 6,468 x 4\n   entity    code   year `Prevalence - Mental and substance use disor…\n   <chr>     <chr> <int>                                         <dbl>\n 1 Afghanis… AFG    1990                                          17.6\n 2 Afghanis… AFG    1991                                          17.8\n 3 Afghanis… AFG    1992                                          18.1\n 4 Afghanis… AFG    1993                                          18.3\n 5 Afghanis… AFG    1994                                          18.4\n 6 Afghanis… AFG    1995                                          18.5\n 7 Afghanis… AFG    1996                                          18.5\n 8 Afghanis… AFG    1997                                          18.5\n 9 Afghanis… AFG    1998                                          18.4\n10 Afghanis… AFG    1999                                          18.4\n# … with 6,458 more rows\n\nNow that we have our packages and data all set up, here is what we will be doing in this section:\nusing dyplr to isolate data (filter, select, arrange, %>%)\nUse select to extract columns\nUse filter to: extract rows\nUse arrange to: move important rows to the top of the data frame (table)\nFirst, we want to rename the prevalence variable from our substance disoder data set because right now it is unnecessarily long. We are going to do this with the janitor package that is very helpful in cleaning names. The janitor packages removes all unique characters and replaces spaces with \"_\". Then we are going to rename using dyplyr to make the name shorter and more convenient. I use a pipe (%>%) here to make this a little easier, and I will describe more how pipes work later.\n\n\n\nExample 1: use select to extract entity (country) column.\nr template:  select(data-frame, column-name) r code: select(substancedisorder, entity)\n\n# A tibble: 6,468 x 1\n   entity     \n   <chr>      \n 1 Afghanistan\n 2 Afghanistan\n 3 Afghanistan\n 4 Afghanistan\n 5 Afghanistan\n 6 Afghanistan\n 7 Afghanistan\n 8 Afghanistan\n 9 Afghanistan\n10 Afghanistan\n# … with 6,458 more rows\n\nExample 2: use select to extract entity, year, and prevalence\nr code: select(substancedisorder, entity, year, prevalence)\n\n# A tibble: 6,468 x 3\n   entity       year prevalence\n   <chr>       <int>      <dbl>\n 1 Afghanistan  1990       17.6\n 2 Afghanistan  1991       17.8\n 3 Afghanistan  1992       18.1\n 4 Afghanistan  1993       18.3\n 5 Afghanistan  1994       18.4\n 6 Afghanistan  1995       18.5\n 7 Afghanistan  1996       18.5\n 8 Afghanistan  1997       18.5\n 9 Afghanistan  1998       18.4\n10 Afghanistan  1999       18.4\n# … with 6,458 more rows\n\nThere are lots of other helper functions we can use with the select() argument. This helps us to selects lots of columns that might have the same suffix or prefix (in addition to many other options).\nExample 3: Using contains() helper function\nr code: select(substancedisorder, contains(\"n\"))\n\n# A tibble: 6,468 x 2\n   entity      prevalence\n   <chr>            <dbl>\n 1 Afghanistan       17.6\n 2 Afghanistan       17.8\n 3 Afghanistan       18.1\n 4 Afghanistan       18.3\n 5 Afghanistan       18.4\n 6 Afghanistan       18.5\n 7 Afghanistan       18.5\n 8 Afghanistan       18.5\n 9 Afghanistan       18.4\n10 Afghanistan       18.4\n# … with 6,458 more rows\n\nThis only selected columns “entity” and “prevalence” since those were the only two columns with an “n” in their name! If we had two columns that both started with the suffix “pre” we could have used the helper starts_with() inside of the select argument.\nTakeaway: We can select whatever columns we want, in many different ways to make our lives easier!\nNow we are going to learn how to use the filter() argument to extract rows of data and turn them into a new data-frame. r template: filter(data-frame, column-name == \"variable-name\") One important thing to note in the filter argument is the double equal sign. Another important thing to notice is that filter extracts rows of an existing data-frame and returns them as a new data-frame.\nExample 4: Filtering rows where entity = Albania\nr code: filter(substancedisorder, entity == \"Albania\")\n\n# A tibble: 28 x 4\n   entity  code   year prevalence\n   <chr>   <chr> <int>      <dbl>\n 1 Albania ALB    1990       11.0\n 2 Albania ALB    1991       11.0\n 3 Albania ALB    1992       11.0\n 4 Albania ALB    1993       11.1\n 5 Albania ALB    1994       11.1\n 6 Albania ALB    1995       11.1\n 7 Albania ALB    1996       11.1\n 8 Albania ALB    1997       11.1\n 9 Albania ALB    1998       11.1\n10 Albania ALB    1999       11.1\n# … with 18 more rows\n\nExample 5: Filtering rows where entity = Afghanistan AND prevalence > 18.0\nr code: filter(substancedisorder, entity == \"Afghanistan\" & prevalence > 18.0)\n\n# A tibble: 11 x 4\n   entity      code   year prevalence\n   <chr>       <chr> <int>      <dbl>\n 1 Afghanistan AFG    1992       18.1\n 2 Afghanistan AFG    1993       18.3\n 3 Afghanistan AFG    1994       18.4\n 4 Afghanistan AFG    1995       18.5\n 5 Afghanistan AFG    1996       18.5\n 6 Afghanistan AFG    1997       18.5\n 7 Afghanistan AFG    1998       18.4\n 8 Afghanistan AFG    1999       18.4\n 9 Afghanistan AFG    2000       18.4\n10 Afghanistan AFG    2001       18.3\n11 Afghanistan AFG    2002       18.1\n\nNote: Afghanistan needs to be a quotation marks because it is character, and prevalence does not need quotation marks because it is numeric.\nSome common mistakes that you want to be sure to avoid are:\nMissing the double equal sign,\nMis-using quotation marks\nNow, we are going to learn how to use the arrange() function. arrange() reorders the way your rows are set up r template: arrange(data-frame, column-name(s))\nNote: you can arrange by a single column name or by multiple columns.\nExample 6: arranging substancedisorder by year:\nr code: arrange(substancedisorder, year)\n\n# A tibble: 6,468 x 4\n   entity               code   year prevalence\n   <chr>                <chr> <int>      <dbl>\n 1 Afghanistan          AFG    1990       17.6\n 2 Albania              ALB    1990       11.0\n 3 Algeria              DZA    1990       14.7\n 4 American Samoa       ASM    1990       10.8\n 5 Andean Latin America <NA>   1990       12.3\n 6 Andorra              AND    1990       14.7\n 7 Angola               AGO    1990       12.5\n 8 Antigua and Barbuda  ATG    1990       13.2\n 9 Argentina            ARG    1990       15.5\n10 Armenia              ARM    1990       10.6\n# … with 6,458 more rows\n\nNote: R automatically arranged the column year in ascending order. Looks what happens when we arrange by code.\nr code: arrange(substancedisorder, code)\n\n# A tibble: 6,468 x 4\n   entity      code   year prevalence\n   <chr>       <chr> <int>      <dbl>\n 1 Afghanistan AFG    1990       17.6\n 2 Afghanistan AFG    1991       17.8\n 3 Afghanistan AFG    1992       18.1\n 4 Afghanistan AFG    1993       18.3\n 5 Afghanistan AFG    1994       18.4\n 6 Afghanistan AFG    1995       18.5\n 7 Afghanistan AFG    1996       18.5\n 8 Afghanistan AFG    1997       18.5\n 9 Afghanistan AFG    1998       18.4\n10 Afghanistan AFG    1999       18.4\n# … with 6,458 more rows\n\nR automatically arranged the column code in alphabetical order.\nExample 7: Lets to arrange substance disorder by both year and prevalence\nr code: arrange(substancedisorder, year, prevalence)\n\n# A tibble: 6,468 x 4\n   entity                code   year prevalence\n   <chr>                 <chr> <int>      <dbl>\n 1 Colombia              COL    1990       10.1\n 2 Mexico                MEX    1990       10.4\n 3 Central Latin America <NA>   1990       10.5\n 4 Azerbaijan            AZE    1990       10.5\n 5 Honduras              HND    1990       10.5\n 6 Tajikistan            TJK    1990       10.6\n 7 Armenia               ARM    1990       10.6\n 8 Panama                PAN    1990       10.7\n 9 Nicaragua             NIC    1990       10.7\n10 Georgia               GEO    1990       10.8\n# … with 6,458 more rows\n\nR first arranged the column year in ascending order and then arranced prevalence within year.\nNote: the order you put the column names matters. The column name you put first will be how your data-frame gets primarily arranged by. Lets see what it looks like if we arrange by prevalence and then year.\nr code: arrange(substancedisorder, prevalence, year)\n\n# A tibble: 6,468 x 4\n   entity  code   year prevalence\n   <chr>   <chr> <int>      <dbl>\n 1 Vietnam VNM    2016       9.72\n 2 Vietnam VNM    2017       9.72\n 3 Vietnam VNM    2015       9.73\n 4 Vietnam VNM    2014       9.74\n 5 Vietnam VNM    2013       9.75\n 6 Vietnam VNM    2012       9.78\n 7 Vietnam VNM    2011       9.80\n 8 Vietnam VNM    2010       9.83\n 9 Vietnam VNM    2009       9.86\n10 Vietnam VNM    2008       9.90\n# … with 6,458 more rows\n\nAs you can see, by simple changing the order of year and prevalence, we get two very different looking data-frames.\nLike I said before, R automatically arranges in ascending order, however, we can change that by using the desc() argument for a column name.\nExample 8: Sort the table first by descending prevalence and then by year:\nr code: arrange(substancedisorder, desc(prevalence), year)\n\n# A tibble: 6,468 x 4\n   entity      code   year prevalence\n   <chr>       <chr> <int>      <dbl>\n 1 New Zealand NZL    2005       19.1\n 2 New Zealand NZL    2004       19.1\n 3 New Zealand NZL    2003       19.1\n 4 New Zealand NZL    2002       19.1\n 5 New Zealand NZL    2006       19.1\n 6 New Zealand NZL    2001       19.1\n 7 New Zealand NZL    2000       19.0\n 8 New Zealand NZL    1999       19.0\n 9 New Zealand NZL    2007       19.0\n10 New Zealand NZL    1998       19.0\n# … with 6,458 more rows\n\nBy doing this, we get the highest prevalence rates first, and then we get the corresponding years.\nThe last thing I want to cover in this section is using a pipe operator which is symbolized in R as %>%. The pipe operator is like saying “then” if we were writing a sentence. So, for example, we can tell R to select a column THEN filter a row THEN arrange that row.\nExample 9: Lets combine select, filter, and arrange by using the pipe operator to select the columns entity, year, and prevalence then filter the row prevalence to include variables higher than 15, then arrange prevalence in descending order.\n\n# A tibble: 1,000 x 3\n   entity       year prevalence\n   <chr>       <int>      <dbl>\n 1 New Zealand  2005       19.1\n 2 New Zealand  2004       19.1\n 3 New Zealand  2003       19.1\n 4 New Zealand  2002       19.1\n 5 New Zealand  2006       19.1\n 6 New Zealand  2001       19.1\n 7 New Zealand  2000       19.0\n 8 New Zealand  1999       19.0\n 9 New Zealand  2007       19.0\n10 New Zealand  1998       19.0\n# … with 990 more rows\n\nAgain, the order that you choose to select, filter, and arrange matters. For example, if you try to filter by a column that is not included in the select() argument, you may run into issues, so be sure to pay close attention!\n\n\nRestructuring Data\nOne important thing to learn when it comes to managing and cleaning data is restructuring, and the difference between tidy and untidy data. Tidy data is a specific structure or format of data that is the easiest to use in R\nThis is how to identify tidy data:\neach variable has its own column, each observation has its own row, and each value has its own cell\nbasically, everything has its own place and it can be easily utilized.\nWith that being said, not all data we encounter will be in tidy format. There’s going to be lots of times that we are given untidy data and we need to make it tidy.\nHere are some functions we can use to make untidy data tidy.\nNote: these methods largley depend on what your untidy data originally looks like. This should’t be considered a solution to all untidy data.\nFunction 1: gather()\nr template: gather(data-frame, old_column1 = \"new_column1\", old_column2 = \"new_column2\") For example, lets say our substancedisorder table had prevalence split up across two columns with n observations in each cell. This would be an example of untidy data. To fix that issue, we could do the following:\nr example code: gather(substancedisorder, key = \"prevalence\", value = \"number of observations\", 2, 3) Doing this would gather the values that were the previous prevalence headers and move them into one column, and then make a new column for number of observations. Note: The “2,3” after making the number of observations column tells R how many columns we are collapsing into one.\nFunction 2: spread()\nr template: spread(data-frame, key = name of key variable, value = name of value variable)\nThe key varible is the variable that stores multiple variables – for example, in our data substancedisorder, the key variable is year. The value variable is the variable containing the actual value being measure. In our data, the value variable is prevalence. The point of the spread() function here is to spread the variables in the key column across their own separate columns.\nExample using spread() r code: spread(substancedisorder, key = year, value = prevalence)\n\n# A tibble: 231 x 30\n   entity       code  `1990` `1991` `1992` `1993` `1994` `1995` `1996`\n   <chr>        <chr>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>\n 1 Afghanistan  AFG     17.6   17.8   18.1   18.3   18.4   18.5   18.5\n 2 Albania      ALB     11.0   11.0   11.0   11.1   11.1   11.1   11.1\n 3 Algeria      DZA     14.7   14.7   14.7   14.7   14.7   14.7   14.7\n 4 American Sa… ASM     10.8   10.8   10.8   10.8   10.8   10.8   10.8\n 5 Andean Lati… <NA>    12.3   12.4   12.4   12.4   12.4   12.4   12.4\n 6 Andorra      AND     14.7   14.7   14.7   14.7   14.7   14.7   14.7\n 7 Angola       AGO     12.5   12.5   12.5   12.5   12.5   12.5   12.5\n 8 Antigua and… ATG     13.2   13.2   13.1   13.1   13.1   13.2   13.2\n 9 Argentina    ARG     15.5   15.5   15.5   15.5   15.6   15.6   15.6\n10 Armenia      ARM     10.6   10.7   10.7   10.7   10.7   10.7   10.7\n# … with 221 more rows, and 21 more variables: 1997 <dbl>,\n#   1998 <dbl>, 1999 <dbl>, 2000 <dbl>, 2001 <dbl>, 2002 <dbl>,\n#   2003 <dbl>, 2004 <dbl>, 2005 <dbl>, 2006 <dbl>, 2007 <dbl>,\n#   2008 <dbl>, 2009 <dbl>, 2010 <dbl>, 2011 <dbl>, 2012 <dbl>,\n#   2013 <dbl>, 2014 <dbl>, 2015 <dbl>, 2016 <dbl>, 2017 <dbl>\n\nThis spreads all the values of year across their own columns, with the prevalence in each cell.\nNote: notice that in the gather() function, we use quotation marks around the new column names, where in spread() we do not use quotation marks at all. This is because in gather() we are actually creating a new variable, but in spread() we are just spreading out already existing variables.\nOne more useful thing that we can learn to help us manage our data is joining data-sets. There will likely be several times where we have two different data sets with useful information and we wish to combine that information into one table.\nOne function that can help us with this is the bind_cols() function. This function is particularly useful when we have two tables that have the same observations in the same order.\nImagine we had two tables for substancedisorder, and the observations were in the same order: 1. Table one had columns entity and year 2. Table two had columns code and prevalence\nHow could we combine this into one big table?\nr template code: table1 %>% bind_cols(table2)\nNow, this seems like a pretty simple way to combine two tables. However, there is a major disadvantage here to take note of. If you are trying to use this method to combine two tables that are quite long, R cannot tell for certain that the rows and observations line up exactly in the correct order. Therefore, I would recommend only using this method when you can be certain everything lines up in the exact same order. For example, to combine two tables that have a very small amount of rows.\nNow, lets say we had two tables for substancedisorder that had the same columns, but different observations.To combine these two tables, we can use the bind_rows() function. This function will essentially stack the tables on top of each other.\nExample: Lets say we had table 1 with the first half of observations for our substancedisorder data and table 2 with the second half of observations for our substancedisorder data. To combine these two tables:\nr template code: table1 %>% bind_rows(table2)\nOften times, there will be situations where you will have duplicate observations when we combine two tables. The way around this issue is to take advantage of the union() function. The union function combines each row that appears in both of the data-sets, but it conveniently removes any duplicate copies.\nr template: table1 %>% union(table2)\nEasy, and convenient!\n\n\nCreating Graphical Displays\nOne of the most important tools in an exploratory analysis is creating graphical displays and visualizations of your data. This helps you to notice any trends, areas of concerns, and to make predictions/hypotheses. In R, one of the most helpful packages for creating these visualizations is ggplot2. Conveniently, ggplot2 is another package that is part of the tidyverse!\nLets look at a data set that shows the share of the population with depression.\n\n# A tibble: 6,468 x 4\n   entity    code   year `Prevalence - Depressive disorders - Sex: Bo…\n   <chr>     <chr> <int>                                         <dbl>\n 1 Afghanis… AFG    1990                                          4.07\n 2 Afghanis… AFG    1991                                          4.08\n 3 Afghanis… AFG    1992                                          4.09\n 4 Afghanis… AFG    1993                                          4.10\n 5 Afghanis… AFG    1994                                          4.10\n 6 Afghanis… AFG    1995                                          4.10\n 7 Afghanis… AFG    1996                                          4.11\n 8 Afghanis… AFG    1997                                          4.11\n 9 Afghanis… AFG    1998                                          4.11\n10 Afghanis… AFG    1999                                          4.12\n# … with 6,458 more rows\n\nAgain, I want to rename the prevalence variable since it is long and will become extremely tedious to use if it is not changed. Refresher on renaming variables: 1. clean it up with the janitor package (this will remove spaces and special characters) 2. use clean_names argument 3. use rename argument. Remember, rename(newname=oldname)\nNote: we are going to do this using the pipe operator like before. Also, note that we can rename multiple variables by separating the variables with a comma. This is a common feature throughout R.\n\n\n\nNow that we have the variable names in an easier-to-use format, we can get on to doing some visualizations! We can make lots of different plots using ggplot2. I will show how to make just a handful of common ones.\nSome important things to know before we start plotting is how ggplot2 works: 1. ggplot2 works in layers 2. the first layer is the dataset 3. the second layer are the coordinates 4. the third layer are the geoms, which are what we choose to visualize our data points\nHere is the very basic template for ggplot that incorporates all 3 layers above:\nggplot(data=data-frame) + geom_ (mapping = aes(x = x-variable, y = y-variable))\nThe argument that you put after “geom_” will tell R what kind of geoms to use, and therefore what kind of plot we are making\nExample 1: Lets make a chart that visualizes the prevalence of a few different countries (lets just choose a few since this data-set has a ton of different countries listed)\nFirst, we need to choose which countries we want to compare. Lets look at: United States, United Kingdom, Mexico, and China. We need to refine our dataset to only include these countries. We can do this by combining some of the skills we learned earlier. Lets try to do this by filtering out rows.\n\n\n\nNow we have a data set containing the countries we want to compare. Now lets visualize this.\n\n\n\nThis produced a plot for us that shows the prevalence of depression for each of the countries we selected. Now we can use this to note some patterns and develop some questions:\nAccording to this data and the chart we produced, we see that the US has the highest prevalence of depression and Mexico has the lowest,\nWe can also see that the UK and China had a slight decrease in the prevalence of depression in the mid-2000s,\nWe can also see that the prevalence of depression in Mexico and the US is on a slight upwards trend.\nOur data only contains information on the prevalence of depression in these countries. However, if we had more information, after looking at this data we could investigate why certain countries are on a downwards trend and some are on an upwards trend. We could potentially look into some demographics such as age, socioeconomic status, employment status, etc. that could help explain what we are seeing visually.\nExample 2: Lets create a side-by-side boxplot for the prevalence of depression by entity so that we can see the spread of data for each country.\n\n\n\nThis produced a nice side-by-side boxplot for us to visualize the spread of depression prevalence for each country we picked. Out of the four countries we picked, we can see that Mexico has the tightest spread of data points, but it does appear to have an outlier.The other three countries have a little bit of a wider spread of data, but no major outliers.\nExample 3: lets create a histogram to look at the distribution of prevalence for our whole dataset:\n\n\n\nThis histogram is showing us the distribution of prevalence in the whole depression dataset. This is telling us that the data looks right-skewed, and that having a prevalence of depression around 3.5-4.0 is the most common\nLastly, I want to quickly go over how to create summaries of our data. Summaries can be beneficial to look at because they give us information on things like: - The range of our data, - a comparison of our mean and median, - and what our standard deviation is.\nThis can be useful information when we want to have the numbers to in addition to the graphics to describe the spread of our data.\nExample 5: summarizing our depression data for the US\n\n# A tibble: 1 x 5\n    max   min  mean median    std\n  <dbl> <dbl> <dbl>  <dbl>  <dbl>\n1  4.84  4.65  4.74   4.77 0.0576\n\nThis gives us a 1x5 tibble containing the max, min, mean, median, and standard deviation of depression prevalence for the US. We can do this for any of the countries in our data set and compare them.\nExample 6: compare the summaries for Mexico and compare to the US:\n\n# A tibble: 1 x 5\n    max   min  mean median    std\n  <dbl> <dbl> <dbl>  <dbl>  <dbl>\n1  2.79  2.64  2.75   2.76 0.0427\n\nLike we saw with our visualizations, we can see that the US has a migher mean for depression prevalence than Mexico. But now, we are able to put specific numbers to that comparison. We now know that the mean prevalence of depression in the US is 4.74 and the mean prevalence of depression in Mexico is 2.75, a difference of 1.99.\nLike I said, creating visualizations is such an important part of data science/statistics so that we can get a full picture of what our data is trying to tell us. With that being said, we need to know the right kinds of plots to make according to our data.Here is a little cheat-sheet to know what kind of plots to make if you are unsure.\nOne variable:\nOne continuous variable: histogram (geom_histogram) or dotplot (geom_dotplot)\nOne discrete variable: bar chart (geom_bar)\nTwo variables:\nBoth continuous: scatter plot (geom_point), line chart (geom_quantile)\nBoth discrete: count chart (geom_count) jitter chart (geom_jitter)\nOne of each: box plot(geom_boxplot), column chart (geom_col)\nThree variables:\ngeom_contour\ngeom_tile\nThere are many more plot options than the ones I just showed you, but these are a good start to knowing how to visualize your data.\n\n\nSimulating Data\nWhy is simulating data important? Simulating data is important in statistics and data science because it allows us to generate random values that could help us validate our modeling and avoid bias.\nHow can we simulate data in R?\nMost people have heard of random number generating in excel, but there is a great way to do this in R too! In R, we can simulate data for different types of probability distributions, like: - Normal distributions, Poisson distributions, and Binomial distributions.\nHere are the functions we can use: 1. norm, 2. dnorm, 3. pnorm, 4. and rpois.\nIn this section I want to focus on simulating random numbers/data, which means we are going to focus on the functions that start with “r” (Ex: rnorm and rpois).\nrnorm: this allows us to simulation normal variates and it also produces a mean and standard devaition of the data rpois: this allows us to simulate random data for a Poisson distribution\nNote: I will mainly be using rnorm here, just remember that this can also be done with rpois.\nHere are some examples:\nExample 1: Let’s start with rnorm, simulating data for a normal distribution for mean = 1 and standard deviation = 0 and n = 10. A normal distribution is one of the first things you learn about in an intro-stats class, and it is one of the most commonly talked about distributions throughout statistics.\nr template: rnorm(n, mean = __, sd = __) r code: rnorm(10, mean = 0, sd = 1)\n\n [1]  0.72338200 -0.29145738 -0.53281224 -0.66074058 -0.06319152\n [6]  1.27502755  1.26652808  1.56988915 -0.02836657  0.35436317\n\nThis generates 10 random numbers for us following the parameters of mean = 0 and sd = 1\nHere’s another way to simulate 10 random numbers for mean = 0 and sd = 1:\nAssign rnorm(10) to x (or anything you want), and then view x. Note: We get different numbers generated between the two methods because this is a random number generator.\nBy assigning rnorm(10) to x, its like telling R to save theses numbers. We will be able to reuse these numbers instead of having new numbers every time.\nNote: By not including mean = 0 and sd = 1 in the example below, R is just assuming mean = 0 and sd = 1 to be the default values.\nx <- rnorm(10)\nx\n\n [1] -0.43398226  1.19192342 -0.05717483 -0.61234341 -0.16691125\n [6] -0.45189679 -0.71939837  0.79771009 -0.83618724 -1.53785681\n\nWhat does it look like if we change the mean and sd from the default values? Let’s look at normal distribution for 50 values, mean = 10, and sd = 5. let’s assign this to the letter r:\nr <- rnorm(50, mean = 10, sd = 5)\nr\n\n [1] 12.122183  9.638608  8.877435  4.637951 12.783859 16.213558\n [7]  9.416814 17.375680 10.533823 19.404536  7.477551 11.233397\n[13] 10.849192 14.178462 13.046885  5.793018 13.656954 10.772188\n[19] 18.140034  9.794177  6.350558 12.752163  7.309125  1.288136\n[25] 24.510008 12.940634  8.659188  9.574049  5.340550 12.553320\n[31]  8.219366  2.927801  5.680411 10.676949  2.339855  8.030313\n[37] 12.524833 18.097365  3.884412 19.727718 17.780980  8.595801\n[43] 16.420528  9.173655  8.926459  9.137858  9.332234  5.779354\n[49]  7.888330  5.612186\n\nWe get 50 random numbers with much larger values than when we did mean = 0 and sd = 1. Lets look at the 5 number summaries for both x and r to compare:\nsummary(x)\nsummary(r)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-1.53786 -0.69263 -0.44294 -0.28261 -0.08461  1.19192 \n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.288   7.580   9.606  10.560  12.901  24.510 \n\nWe see that when comparing the summaries of r and x, r has a much larger range of values and that the median and mean are both much higher. This was to be expected since we increased the mean and sd of r!\nNow that we learned the basics of how to produce random numbers, we need to learn how to make these numbers/results reproducible. We can do this by setting a seed. The set.seed() function does this for us. When you set the seed, you can set it to any number you want, just be sure it is something easy to remember and simple to use (i.e. I wouldn’t recommend using a 10-digit number as that could become annoying to use and it could become easy to make a typo).\nExample: Lets set the seed for using the same mean and sd we used above (mean = 20 and sd = 5)\nset.seed(1) rnorm (50, mean = 20, sd = 5)\n\n [1] 16.867731 20.918217 15.821857 27.976404 21.647539 15.897658\n [7] 22.437145 23.691624 22.878907 18.473058 27.558906 21.949216\n[13] 16.893797  8.926501 25.624655 19.775332 19.919049 24.719181\n[19] 24.106106 22.969507 24.594887 23.910682 20.372825 10.053242\n[25] 23.099129 19.719356 19.221022 12.646238 17.609250 22.089708\n[31] 26.793398 19.486061 21.938358 19.730975 13.114702 17.925027\n[37] 18.028550 19.703433 25.500127 23.815879 19.177382 18.733192\n[43] 23.484817 22.783316 16.556222 16.462524 21.822910 23.842665\n[49] 19.438269 24.405539\n\nThis ensures that whenever we use seed(1), we get the same numbers we produced with the rnorm statement above.\nSimulating random numbers can be a useful thing to do as a statistician, however, we are also able to simulate results/values that come from a specific model that we want to validate.\nLets simulate numbers from a simple linear regression model using a normal distribution! Remember, a SLR line equation looks like this:\ny = beta_0 + (beta_1 * x) + e\nThis means we need to simulate the values for x and e separately!\nFirst, lets set the seed: set.seed(5)\n\n\n\nNext, lets simulate x (lets do 200 values, mean = 5, sd = 1): x <- rnorm(200, mean = 5, sd = 1) x\n\n  [1] 4.159145 6.384359 3.744508 5.070143 6.711441 4.397092 4.527834\n  [8] 4.364629 4.714226 5.138108 6.227630 4.198221 3.919607 4.842466\n [15] 3.928240 4.861014 4.402687 2.816033 5.240817 4.740645 5.900512\n [22] 5.941869 6.467962 5.706761 5.819009 4.706518 6.418589 6.498774\n [29] 4.342918 4.147205 5.315915 6.109694 7.215461 6.217104 6.479222\n [36] 5.951574 3.990467 2.999527 3.237814 4.857392 6.550060 4.197577\n [43] 4.925421 6.895668 4.543431 5.562223 4.112991 4.539755 4.275672\n [50] 4.930789 6.463249 5.187726 6.022023 4.408165 4.887799 4.075047\n [57] 5.753305 4.887391 4.935909 5.233275 3.863417 5.854830 4.421630\n [64] 5.496362 4.239942 4.658614 2.897671 4.698298 3.727617 4.720334\n [71] 4.795903 4.774386 5.347028 5.032368 5.413531 4.844652 5.973485\n [78] 5.121090 5.189174 4.437115 5.498416 3.257698 5.975529 4.975917\n [85] 5.675684 4.289690 7.387233 4.526568 4.924227 4.478160 5.926047\n [92] 3.937589 5.557034 5.900731 5.989946 5.383608 4.653416 4.459811\n [99] 4.817444 4.940700 3.004613 6.135311 5.675795 5.208483 4.942154\n[106] 5.893811 4.771135 3.034347 4.246490 6.280152 4.047095 6.622379\n[113] 7.600142 5.139649 3.649280 5.798931 3.445004 5.463720 5.052430\n[120] 4.797968 6.170856 5.884845 3.682111 3.356749 6.059250 5.290084\n[127] 4.599967 6.243096 3.633589 3.558587 6.348549 3.021472 3.759049\n[134] 4.895961 5.732973 5.455680 5.288080 3.926309 5.648743 5.299162\n[141] 4.204005 4.970647 7.180236 5.957418 4.694951 4.581597 5.099954\n[148] 4.770190 3.584785 4.607401 5.946089 5.751771 4.482623 5.808336\n[155] 4.385465 6.238259 4.661905 6.196366 4.556682 5.186115 2.378655\n[162] 7.246255 5.093432 6.627280 4.489082 4.340619 4.959810 4.881306\n[169] 4.980343 4.514322 3.559852 5.143769 3.765413 3.247499 4.964504\n[176] 5.332035 6.572288 3.930529 5.916287 4.405007 7.181647 4.316227\n[183] 5.750059 5.974383 3.735527 4.722579 4.810601 4.615975 5.740588\n[190] 3.831662 5.667539 5.366237 4.485057 5.450568 4.812280 6.339069\n[197] 5.816219 5.082202 4.349137 5.726409\n\nNext, lets simulate the error term (200 values, mean = 5, sd = 2): e <- rnorm(200, mean = 5, sd = 2) e\n\n  [1]  4.7726436  4.4097983  6.9783369  3.4497364  5.5517965\n  [6]  5.8215633  6.2223663  6.8731414  4.2649166  6.4807535\n [11]  7.4370661  6.2582689  6.0554926  4.0554894  6.6474303\n [16]  4.1444235  4.7147121  7.8375661  5.9742678  6.2068829\n [21]  5.4216658  4.9334016  9.0503940  4.2584265  1.8435311\n [26]  4.7568561  1.4066464  4.0488169  3.2317954 -1.9961180\n [31]  4.2360333  6.9553763  3.8839181  3.7470897  3.9390975\n [36]  8.7952432  7.7910814  3.5079483  4.3888538  7.3393563\n [41]  5.6087744  4.7650035  4.8798289  7.9418779  2.0437048\n [46]  3.6327741  5.9210812  4.6369961  2.6823674  5.8180378\n [51]  4.4835859  4.4662011  5.3283119  4.2130821  1.3125255\n [56]  1.9154235  3.8275193  3.2957222  6.5566491  4.9393659\n [61]  2.0886848  5.1875698  6.9646984  3.8065797  5.1496097\n [66]  9.3948589  6.5900464  3.9221156  1.7974336  3.5372529\n [71]  4.2885184  3.0291714  3.5376587  7.9306482  8.7172306\n [76]  5.0069941  2.3124495  5.3025881  5.5800183  4.7550433\n [81]  5.2503088  3.4551318  2.9740678  6.9338392  4.1533454\n [86]  3.3368011  7.7999145  5.0340279  8.6949939  3.6273212\n [91]  4.5625519  6.3651858  6.0482600  5.1611000  5.1075711\n [96]  3.5254820  6.9328761  6.9686137  5.3745819  5.5459715\n[101]  7.4202922  5.3773143  8.9249973  5.2774239  1.8427453\n[106]  3.4059575  7.4487078  4.2693329  4.6748194  6.1209584\n[111]  3.2785487  7.4772690  6.5348715  2.8251818  5.1350075\n[116]  8.2102811  7.4644589  4.2417724  2.3002668  5.7298362\n[121]  4.2728102  7.7493066  5.5837915  6.4211834  3.1244782\n[126]  2.7718737  6.2687439  4.5376142  2.2636116  3.4901851\n[131]  2.7488067  4.5612815  4.7313841  3.3639588  5.9446683\n[136]  3.2614877  2.3354233  5.1411257  5.9281864  5.5783170\n[141] -0.7698822  0.3306164  1.5382179  6.6500192  2.9099209\n[146]  3.2456133  4.1992203  2.4636221  5.2771728  7.3671432\n[151]  0.7788899  5.5213522  6.8911337  3.7600788  4.9817985\n[156]  6.0404508  8.6125174  1.1749602  5.3985642  5.5529699\n[161]  3.3274471  9.0591948  5.8582120  7.1278957  3.7883539\n[166]  7.1487461  3.5753047  4.6422797  5.9995201  4.6008577\n[171]  5.1797896  7.0098201  1.2541167  6.0495691  3.9707453\n[176]  7.4218651  3.9744092  7.1812513  5.9836898  4.5147421\n[181]  9.2320945  7.3772791  6.7905224  6.7370813  8.3123559\n[186]  7.8912720  6.4892009  3.6196196  3.4171765  4.4758376\n[191]  4.1841658  5.4026221  3.5361050  6.4582714  5.6532972\n[196] -0.4157558  3.8157222  6.0090874  1.9546058  4.2822496\n\nNow, lets put these values in the SLR model: y <- 10 + 2 * x + e y\n\n  [1] 23.09093 27.17852 24.46735 23.59002 28.97468 24.61575 25.27803\n  [8] 25.60240 23.69337 26.75697 29.89233 24.65471 23.89471 23.74042\n [15] 24.50391 23.86645 23.52009 23.46963 26.45590 25.68817 27.22269\n [22] 26.81714 31.98632 25.67195 23.48155 24.16989 24.24382 27.04636\n [29] 21.91763 16.29829 24.86786 29.17476 28.31484 26.18130 26.89754\n [36] 30.69839 25.77202 19.50700 20.86448 27.05414 28.70890 23.16016\n [43] 24.73067 31.73321 21.13057 24.75722 24.14706 23.71651 21.23371\n [50] 25.67962 27.41008 24.84165 27.37236 23.02941 21.08812 20.06552\n [57] 25.33413 23.07050 26.42847 25.40592 19.81552 26.89723 25.80796\n [64] 24.79930 23.62949 28.71209 22.38539 23.31871 19.25267 22.97792\n [71] 23.88032 22.57794 24.23172 27.99538 29.54429 24.69630 24.25942\n [78] 25.54477 25.95837 23.62927 26.24714 19.97053 24.92513 26.88567\n [85] 25.50471 21.91618 32.57438 24.08716 28.54345 22.58364 26.41465\n [92] 24.24036 27.16233 26.96256 27.08746 24.29270 26.23971 25.88824\n [99] 25.00947 25.42737 23.42952 27.64794 30.27659 25.69439 21.72705\n[106] 25.19358 26.99098 20.33803 23.16780 28.68126 21.37274 30.72203\n[113] 31.73516 23.10448 22.43357 29.80814 24.35447 25.16921 22.40513\n[120] 25.32577 26.61452 29.51900 22.94801 23.13468 25.24298 23.35204\n[127] 25.46868 27.02381 19.53079 20.60736 25.44590 20.60422 22.24948\n[134] 23.15588 27.41061 24.17285 22.91158 22.99374 27.22567 26.17664\n[141] 17.63813 20.27191 25.89869 28.56486 22.29982 22.40881 24.39913\n[148] 22.00400 22.44674 26.58195 22.67107 27.02489 25.85638 25.37675\n[155] 23.75273 28.51697 27.93633 23.56769 24.51193 25.92520 18.08476\n[162] 33.55170 26.04508 30.38246 22.76652 25.82998 23.49492 24.40489\n[169] 25.96021 23.62950 22.29949 27.29736 18.78494 22.54457 23.89975\n[176] 28.08593 27.11899 25.04231 27.81626 23.32476 33.59539 26.00973\n[183] 28.29064 28.68585 25.78341 27.33643 26.11040 22.85157 24.89835\n[190] 22.13916 25.51924 26.13510 22.50622 27.35941 25.27786 22.26238\n[197] 25.44816 26.17349 20.65288 25.73507\n\nLast, lets look at the summary of our model and make a simple plot of our values for x and y: summary(y) plot(x,y)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  16.30   23.15   25.03   25.01   26.89   33.60 \n\n\nDone! We just successfully simulated a SLR model that follows a normal disrtibution! The awesome thing is, we can do this for all sorts of distributions too like binary and poisson distributions!\nTo do this for a binary distribution, we would have used the rbinom() argument instead.\nTo do this for a Poisson distribution, we would have used the rpois argument, and taken the exponential value of the mean from a normal distribution.\nExample of how to simulate a Poisson distrubution model:\nAgain, this super important to set the seed so we can reproduce these results! r code: set.seed(10)\n\n\n\nThis simulates the predictor variable x as before: r code: x_norm <- rnorm (200, mean = 0, sd = 1)\n\n\n\nThis calculates the log mean of the model: r code: log_mean <- 5 + 1 * x_norm\n\n\n\nThis takes the exponential value to make it a Poisson distrubution: r code: y_pois <- rpois (200, exp(log_mean))\n\n\n\nAs before, this gives us the 5-number summary: r code: summary(y_pois)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   11.0    65.5   134.0   203.1   279.2  1371.0 \n\nAgain, as before, this gives us a basic y vs x plot that shows us what our model looks like. r code: plot(x_norm, y_pois)\n\n\n\nDone! We successfully simulated random data, an SLR model, and a Poisson Distribution!\n\n\nCommon Errors in R\nWhen you are new to a programming language, it is easy to get frustrated when errors occur. Especially if you don’t understand what those error messages are trying to tell you. Most of the time, error messages can be resolved pretty easily if you know what to look for. Below are some of the most common error messages, and some things to go back and double check your code for in attempt to resolve the error.\n1. Error message: “could not find function”\nWhat it means: this means that r could not find the function you are trying to use. How to fix this: first, always double check that you do not have any typos. Remember - R is case sensitive, so make sure you keep your cases consistent. This could also mean that the package required to use this function is not loaded. Double check that all your necessary packages are loaded, and worst case scenario, save your work, restart R, and reload your packages.\n2. Error message: \"Error in if:\nWhat it means: this means that there is an issue in your conditional statement. How to fix this: make sure that your data is logical, and that there aren’t any missing values messing up your conditional statement(s).\n3. Error message: “Error in eval”\nWhat it means: This means that you have probably referenced an object that doesn’t exist. How to fix this: Make sure that there are no typos, and that you are being mindful about case-sensitivity.\n4. Error message: “cannot open the connections”\nWhat it means: This likely means that a file or a connection cannot be opened simply because R cannot find it. How to fix it: make sure that if you are using a file path, that this path is correct.As always, make sure there are not typos or case issues and make sure that you are not missing something like a forward slash.\n5. Error message: “unexpected symbol in…”\nWhat it means: This is a simple fix and likely means that you just forgot to add a comma somewhere. How to fix it: Go back to your code and make sure commas and other punctuation are in the correct spot.\nOf course, there is so much more to learn about R here than what I showed you. However, these are the basics and will set you on the right track to creating some amazing projects in R.\nAs a last note, I want to leave everyone with some more resources to help expand your ability to use R in addition to the resources I used to create this website and its content.\nSources\nhttps://www.rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf https://happygitwithr.com/rstudio-git-github.html https://www.apreshill.com/blog/2020-12-postcards-distill/ https://www.rstudio.com/resources/cheatsheets/ https://www.r-bloggers.com/2016/06/common-r-programming-errors-faced-by-beginners/\n\n\n\n",
      "last_modified": "2021-12-16T17:44:22+00:00"
    }
  ],
  "collections": []
}
